{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30494751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sodapy import Socrata\n",
    "from pymongo import MongoClient\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "#PostgreSql related operations such as reading and writing\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "\n",
    "#Visulalization\n",
    "import pandas.io.sql as sqlio\n",
    "import psycopg2\n",
    "from pandas.io.json import json_normalize\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Arc, Rectangle, ConnectionPatch\n",
    "from matplotlib.offsetbox import  OffsetImage\n",
    "from functools import reduce as rd\n",
    "\n",
    "#Ignoring Warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497e0764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "#accessing the data from mongoDB cloud and loading it to the dataframe\n",
    "#client = MongoClient()\n",
    "client = MongoClient('localhost', 27017)\n",
    "#selecting database\n",
    "db = client['DAPDATABASES']\n",
    "#selecting the collection within the database\n",
    "data = db.Restaurant_Features\n",
    "#converting entire collection to Pandas dataframe\n",
    "data1_raw= pd.DataFrame(list(data.find()))\n",
    "#printing the dataframe named data\n",
    "print(data1_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4fa86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#displaying heatmap for visualizing null values in rawdataset\n",
    "sns.heatmap(data1_raw.isnull(), cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9e76af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c538544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b42a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the unnecessary columns from the rawdata dataframe and saving it in another dataframe called data1_remove\n",
    "data1_remove=data1_raw.drop(['_id','index','objectid','globalid','doing_business_as_dba','bulding_number','business_address','food_service_establishment','sidewalk_dimensions_length','sidewalk_dimensions_width','roadway_dimensions_length','roadway_dimensions_width','sla_serial_number','landmark_district_or_building','landmarkdistrict_terms','healthcompliance_terms','community_board','council_district','census_tract','bin','bbl','nta'],axis=1)\n",
    "data1_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43ec4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the column names of dataframe named data1_remove to confirm whether the unwanted colums are removed or not\n",
    "data1_remove.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3225feea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding null values in all the columns in data1_remove using sum function\n",
    "data1_remove.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9c288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns for merging dataframes to create the resultant dataset using inner joint\n",
    "data1_remove.rename(columns = {'zip':'zipcode'}, inplace = True)\n",
    "data1_remove.rename(columns={'borough':'county'},inplace=True)\n",
    "#displaying the first 1 row of the data1_remove to check whether the name of the row changed or not\n",
    "data1_remove.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05fc4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all other columns except continuous data columns from data1_remove to perforn KNN imputation\n",
    "data1_imputation=data1_remove.drop([\"zipcode\",\"seating_interest_sidewalk\",\"restaurant_name\",\"legal_business_name\",\"street\",\"county\",\"approved_for_sidewalk_seating\",\"approved_for_roadway_seating\",\"qualify_alcohol\",\"sla_license_type\",\"time_of_submission\"],axis=1)\n",
    "data1_imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbdacbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using KNN algorithm to fill the null values in the data1_imputation dataframe,which contains only numerical data columns\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "data1_imputed = imputer.fit_transform(data1_imputation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f577af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying the tranformed data stored as an array in the variable called data1_imputed ,after filled the null values\n",
    "data1_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce85359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the array values in data1_imputed variable is loaded to new dataframe data1_after_imputed  \n",
    "data1_after_imputed=pd.DataFrame(data1_imputed,columns=['sidewalk_dimensions_area','latitude','longitude','roadway_dimensions_area'])\n",
    "#displaying the dataframe data1_af_imputed\n",
    "data1_after_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68727df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the null values in data1_after_imputed\n",
    "data1_after_imputed.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90ac376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing pairplot for data1_after_imputed dataframe to check the linearity by using seaborn  \n",
    "sns.pairplot(data1_after_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474a2490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking correlation between all the columns in data1_after_imputed\n",
    "data1_after_imputed.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdea825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking number of categories and its counts in the column- sla_licence_type, in data1_remove dataframe\n",
    "data1_remove['sla_license_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0c3a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using algorithm -filling null values with most frequent values in sla_license_type \n",
    "data1_remove[\"sla_license_type\"].fillna('OP', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1357fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all the continuous data columns from data1_remove dataframe and storing all other columns in another dataframe named data1_after_remove\n",
    "# to concade with the data1_after_imputed which holds all the imputed continuous variables\n",
    "data1_after_remove=data1_remove.drop(['sidewalk_dimensions_area','latitude','longitude','roadway_dimensions_area'],axis=1)\n",
    "data1_after_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bb9976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concading the data1_after_imputed and data1_after_remove after cleaning and imputation and removing unwanted variables\n",
    "data1_clean = pd.concat([data1_after_imputed, data1_after_remove],axis=1)\n",
    "# viewing the cleaned dataset after imputation and cleaning \n",
    "display(data1_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf0e75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for null values in data1_clean data set\n",
    "data1_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a932bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearranging the columns and storing it into the data1_final dataframe\n",
    "data1_final = data1_clean[['restaurant_name','zipcode','county','legal_business_name','latitude','longitude','approved_for_sidewalk_seating','sidewalk_dimensions_area','seating_interest_sidewalk','approved_for_roadway_seating','roadway_dimensions_area','qualify_alcohol','sla_license_type','time_of_submission']]\n",
    "# checking for null values\n",
    "data1_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['DAPDATABASES']\n",
    "data = db['Restaurant_Inspection']\n",
    "data2_raw= pd.DataFrame(list(data.find()))\n",
    "print(data2_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a13f0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(data2_raw.isnull(),cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a2967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd91f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dd8468",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_remove=data2_raw.drop(['_id','index','street','statecode','deficiency_number','deficiency_description'],axis=1)\n",
    "data2_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abc7730",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_remove.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592bc6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_remove.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30db7df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#geocoded_column in data2_remove is applied pandas series package to split the dictionary into separate dataframe\n",
    "#and loading it in a dataframe called geocoded_columnnew\n",
    "data2_remove=data2_remove.dropna()\n",
    "data2_remove.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55746316",
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoded_columnnew=data2_remove['georeference'].apply(pd.Series)\n",
    "geocoded_columnnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a92ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoded_columnnew=geocoded_columnnew.drop(columns=[\"type\"])\n",
    "geocoded_columnnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d0d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoded_columnnew=pd.DataFrame(geocoded_columnnew['coordinates'].tolist(), index=geocoded_columnnew.index)\n",
    "geocoded_columnnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf619e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoded_columnnew = geocoded_columnnew.rename(columns={0: 'latitude',1: 'longitude'})\n",
    "geocoded_columnnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a46347",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_after_split=pd.DataFrame(geocoded_columnnew,columns=['latitude','longitude'])\n",
    "data2_after_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_after_split.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b44e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_concat= pd.concat([data2_remove,data2_after_split],axis=1)\n",
    "data2_clean=data2_concat.drop(['georeference'],axis=1)\n",
    "display(data2_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5550b344",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c7ad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_clean.rename(columns = {'trade_name':'restaurant_name'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee4435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_final = data2_clean[['zipcode','county','city','owner_name','restaurant_name','latitude','longitude','inspection_grade','inspection_date']]\n",
    "data2_final.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46783358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['DAPDATABASES']\n",
    "data = db['Restaurant_Liquor']\n",
    "data3_raw = pd.DataFrame(list(data.find()))\n",
    "print(data3_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608e5c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3_reduce=pd.DataFrame(data3_raw)\n",
    "data3_reduce.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3_remove=data3_reduce.drop(['_id','index','serial_number','premise_address','premise_city','premise_address_2','other','dba','days_hours_of_operation',':@computed_region_yamh_8v7k',':@computed_region_kjdx_g34t',':@computed_region_wbg7_3whc','method_of_operation','license_issued_date','license_expiration_date','zone','effective_date','original_date'],axis=1)\n",
    "data3_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099bcd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3_remove.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36df0792",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3_remove['premise_state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85a79af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3_remove = data3_remove[data3_remove.premise_state == 'NY']\n",
    "data3_remove['premise_state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e723697",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3_remove.rename(columns = {'premise_zip':'zipcode'}, inplace = True)\n",
    "data3_remove.rename(columns = {'premise_name':'restaurant_name'}, inplace = True)\n",
    "data3_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2232f2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3_remove=data3_remove.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e92c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3_remove.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75396d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoded_columnnew=data3_remove['georeference'].apply(pd.Series)\n",
    "geocoded_columnnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3574e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoded_columnnew=geocoded_columnnew.drop(columns=[\"type\"])\n",
    "geocoded_columnnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cf3c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoded_columnnew=pd.DataFrame(geocoded_columnnew['coordinates'].tolist(), index=geocoded_columnnew.index)\n",
    "geocoded_columnnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680e29f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoded_columnnew = geocoded_columnnew.rename(columns={0: 'latitude',1: 'longitude'})\n",
    "geocoded_columnnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb93903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3_after_split=pd.DataFrame(geocoded_columnnew,columns=['latitude','longitude'])\n",
    "data3_after_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63022f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3_after_split.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecd6134",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3_concat= pd.concat([data3_remove,data3_after_split],axis=1)\n",
    "data3_clean=data3_concat.drop(['georeference'],axis=1)\n",
    "display(data3_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7996a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd94fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3_final = data3_clean[['zipcode','county','premise_state','restaurant_name','latitude','longitude','license_type_code','license_class_code','certificate_number']]\n",
    "data3_final.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35230208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "try:\n",
    "    dbConnection = psycopg2.connect(\n",
    "        user = \"dap\",\n",
    "        password = \"dap\",\n",
    "        host = \"127.0.0.1\",\n",
    "        port = \"5432\",\n",
    "        database = \"postgres\")\n",
    "    dbConnection.set_isolation_level(0) # AUTOCOMMIT\n",
    "    dbCursor = dbConnection.cursor()\n",
    "    dbCursor.execute('CREATE DATABASE dapproject;')\n",
    "    dbCursor.close()\n",
    "except (Exception , psycopg2.Error) as dbError :\n",
    "    print (\"Error while connecting to PostgreSQL\", dbError)\n",
    "finally:\n",
    "    if dbConnection in locals(): \n",
    "        dbConnection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32a6395",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine =sqlalchemy.create_engine('postgresql://dap:dap@localhost:5432/dapproject')\n",
    "con = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389c6f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if any table exists\n",
    "print(\"The tables present in the dapproject database before storing are:\")\n",
    "print(engine.table_names());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c43dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name='RestaurantFeatures'\n",
    "data1_final.to_sql(table_name, con, if_exists = 'replace', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb774ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine =sqlalchemy.create_engine('postgresql://dap:dap@localhost:5432/dapproject')\n",
    "con = engine.connect()\n",
    "\n",
    "# checking if any table exists\n",
    "print(\"The tables present in the dapproject database before storing are:\")\n",
    "print(engine.table_names());\n",
    "\n",
    "table_name='RestaurantInspection'\n",
    "data2_final.to_sql(table_name, con, if_exists = 'replace', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075ec9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine =sqlalchemy.create_engine('postgresql://dap:dap@localhost:5432/dapproject')\n",
    "con = engine.connect()\n",
    "\n",
    "# checking if any table exists\n",
    "print(\"The tables present in the dapproject database before storing are:\")\n",
    "print(engine.table_names());\n",
    "\n",
    "table_name='RestaurantLiquor'\n",
    "data3_final.to_sql(table_name, con, if_exists = 'replace', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9d1753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if any table exists\n",
    "print(\"The tables present in the dap_projectt database before storing are:\")\n",
    "print(engine.table_names());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e64eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import psycopg2\n",
    "# import pprint\n",
    "\n",
    " \n",
    "\n",
    "# #Define our connection string\n",
    "# conn_string = \"host='127.0.0.1' port = '5432' dbname='dapproject' user = 'dap' password = 'dap'\"\n",
    "\n",
    " \n",
    "\n",
    "# # print the connection string we will use to connect\n",
    "# print (\"Connecting to database\\n ->%s\" % (conn_string))\n",
    "\n",
    " \n",
    "\n",
    "# # get a connection, if a connect cannot be made an exception will be raised here\n",
    "# conn = psycopg2.connect(conn_string)\n",
    "\n",
    " \n",
    "\n",
    "# # conn.cursor will return a cursor object, you can use this cursor to perform queries\n",
    "# cursor = conn.cursor()\n",
    "# print (\"Connected!\\n\")\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "# # execute our Query\n",
    "# cursor.execute(\"SELECT * FROM information_schema.columns WHERE table_schema = ('public') AND table_name   = ('RestaurantFeatures')\")\n",
    "# #cursor.execute(\"SELECT * FROM RestaurantFeatures\")\n",
    "\n",
    " \n",
    "\n",
    "# # retrieve the records from the database\n",
    "# records = cursor.fetchall()\n",
    "\n",
    " \n",
    "\n",
    "# # print out the records using pretty print\n",
    "# # note that the NAMES of the columns are not shown, instead just indexes.\n",
    "# # for most people this isn't very useful so we'll show you how to return\n",
    "# # columns as a dictionary (hash) in the next example.\n",
    "# pprint.pprint(records)\n",
    "\n",
    "# cursor.execute(\"\"\"SELECT table_name FROM information_schema.tables\n",
    "#        WHERE table_schema = 'public'\"\"\")\n",
    "# for table in cursor.fetchall():\n",
    "#     print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9c0316",
   "metadata": {},
   "outputs": [],
   "source": [
    "RestaurantInspection_df = data2_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805f4f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "RestaurantFeatures_df = data1_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9503231",
   "metadata": {},
   "outputs": [],
   "source": [
    "RestaurantLiquor_df = data3_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8f8f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b1ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9cfb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fb7fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3de6ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c8a630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198063ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6078d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8962e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
